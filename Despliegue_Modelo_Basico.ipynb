{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DESPLIEGUE (puesta en producción)\n",
    "\n",
    "**Luego de haber cubierto muchas etapas de Ciencia de Datos, se hará un ejercicio completo que va desde la creación de un modelo, hasta el despliegue del mismo a través de un sitio web**\n",
    "\n",
    "# Datos\n",
    "\n",
    "Para este ejercicio se usará uno de los conjuntos de datos más comunes en el estudio de Data Science: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), que es sobre flores. \n",
    "\n",
    "**Tomado de Wikipedia:**\n",
    "\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gaspé Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
    "\n",
    "El conjunto de datos consta de 50 muestras de cada una de las tres especies de las Iris (Iris setosa, Iris virginica e Iris versicolor). Se midieron cuatro características de cada muestra: la longitud y el ancho de los pétalos y sépalos, en centímetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"./data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_sepalo</th>\n",
       "      <th>ancho_sepalo</th>\n",
       "      <th>long_petalo</th>\n",
       "      <th>ancho_petalo</th>\n",
       "      <th>especie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_sepalo  ancho_sepalo  long_petalo  ancho_petalo      especie\n",
       "0          5.1           3.5          1.4           0.2  Iris-setosa\n",
       "1          4.9           3.0          1.4           0.2  Iris-setosa\n",
       "2          4.7           3.2          1.3           0.2  Iris-setosa\n",
       "3          4.6           3.1          1.5           0.2  Iris-setosa\n",
       "4          5.0           3.6          1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Características \"Features\" y Meta \"Target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('especie',axis = 1)\n",
    "y = iris['especie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['especie'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias formas de hacer \"one-hot encode\"\n",
    "\n",
    "https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
    "\n",
    "https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "codificador = LabelBinarizer()\n",
    "y = codificador.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno, X_prueba, y_entreno, y_prueba = train_test_split(X, \n",
    "                                                            y, \n",
    "                                                            test_size = 0.2, \n",
    "                                                            random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar la escala de los datos - Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizador.fit(X_entreno.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entreno_normalizado = normalizador.transform(X_entreno.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prueba_normalizado = normalizador.transform(X_prueba.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelo\n",
    "\n",
    "\n",
    "### Crear el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(units = 4,\n",
    "                 activation = 'relu',\n",
    "                 input_shape = [4,]))\n",
    "\n",
    "# Ultima capa para clasificación multi-clase              \n",
    "#    de las tres especies\n",
    "modelo.add(Dense(units = 3,\n",
    "                 activation = 'softmax'))\n",
    "\n",
    "modelo.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "detencion_temprana = EarlyStopping(patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 56ms/step - loss: 1.0545 - accuracy: 0.3583 - val_loss: 1.0862 - val_accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0496 - accuracy: 0.3667 - val_loss: 1.0810 - val_accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0444 - accuracy: 0.3833 - val_loss: 1.0761 - val_accuracy: 0.3667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0395 - accuracy: 0.3917 - val_loss: 1.0714 - val_accuracy: 0.3667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0351 - accuracy: 0.4250 - val_loss: 1.0667 - val_accuracy: 0.4000\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0309 - accuracy: 0.4500 - val_loss: 1.0621 - val_accuracy: 0.4000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0264 - accuracy: 0.5000 - val_loss: 1.0578 - val_accuracy: 0.4333\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0221 - accuracy: 0.5583 - val_loss: 1.0534 - val_accuracy: 0.5333\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0179 - accuracy: 0.6083 - val_loss: 1.0490 - val_accuracy: 0.5667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0135 - accuracy: 0.6583 - val_loss: 1.0448 - val_accuracy: 0.6000\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0092 - accuracy: 0.6667 - val_loss: 1.0405 - val_accuracy: 0.6000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0049 - accuracy: 0.6667 - val_loss: 1.0363 - val_accuracy: 0.6000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0006 - accuracy: 0.6833 - val_loss: 1.0322 - val_accuracy: 0.6000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9963 - accuracy: 0.6833 - val_loss: 1.0280 - val_accuracy: 0.6000\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9921 - accuracy: 0.6833 - val_loss: 1.0239 - val_accuracy: 0.6000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9879 - accuracy: 0.6833 - val_loss: 1.0197 - val_accuracy: 0.6000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9836 - accuracy: 0.6833 - val_loss: 1.0155 - val_accuracy: 0.6000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9793 - accuracy: 0.6833 - val_loss: 1.0115 - val_accuracy: 0.6000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9749 - accuracy: 0.6833 - val_loss: 1.0076 - val_accuracy: 0.6000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9708 - accuracy: 0.6833 - val_loss: 1.0035 - val_accuracy: 0.6000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9665 - accuracy: 0.6833 - val_loss: 0.9995 - val_accuracy: 0.6000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9622 - accuracy: 0.6833 - val_loss: 0.9954 - val_accuracy: 0.6000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9580 - accuracy: 0.6833 - val_loss: 0.9913 - val_accuracy: 0.6000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9537 - accuracy: 0.6833 - val_loss: 0.9874 - val_accuracy: 0.6000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9496 - accuracy: 0.6833 - val_loss: 0.9832 - val_accuracy: 0.6000\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9453 - accuracy: 0.6833 - val_loss: 0.9793 - val_accuracy: 0.6000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9411 - accuracy: 0.6833 - val_loss: 0.9752 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9367 - accuracy: 0.6833 - val_loss: 0.9712 - val_accuracy: 0.6000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9326 - accuracy: 0.6833 - val_loss: 0.9672 - val_accuracy: 0.6000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9282 - accuracy: 0.6833 - val_loss: 0.9632 - val_accuracy: 0.6000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9241 - accuracy: 0.6833 - val_loss: 0.9592 - val_accuracy: 0.6000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9199 - accuracy: 0.6833 - val_loss: 0.9551 - val_accuracy: 0.6000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9156 - accuracy: 0.6833 - val_loss: 0.9512 - val_accuracy: 0.6000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9114 - accuracy: 0.6833 - val_loss: 0.9471 - val_accuracy: 0.6000\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9072 - accuracy: 0.6833 - val_loss: 0.9433 - val_accuracy: 0.6000\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9029 - accuracy: 0.6833 - val_loss: 0.9393 - val_accuracy: 0.6000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8988 - accuracy: 0.6833 - val_loss: 0.9352 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8944 - accuracy: 0.6833 - val_loss: 0.9314 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8903 - accuracy: 0.6833 - val_loss: 0.9276 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8861 - accuracy: 0.6833 - val_loss: 0.9237 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8818 - accuracy: 0.6833 - val_loss: 0.9199 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8776 - accuracy: 0.6833 - val_loss: 0.9160 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8735 - accuracy: 0.6833 - val_loss: 0.9119 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8692 - accuracy: 0.6833 - val_loss: 0.9081 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8651 - accuracy: 0.6833 - val_loss: 0.9042 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8610 - accuracy: 0.6833 - val_loss: 0.9006 - val_accuracy: 0.6000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8568 - accuracy: 0.6833 - val_loss: 0.8967 - val_accuracy: 0.6000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8526 - accuracy: 0.6833 - val_loss: 0.8927 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8484 - accuracy: 0.6833 - val_loss: 0.8890 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8443 - accuracy: 0.6833 - val_loss: 0.8852 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8402 - accuracy: 0.6833 - val_loss: 0.8813 - val_accuracy: 0.6000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8361 - accuracy: 0.6833 - val_loss: 0.8774 - val_accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8320 - accuracy: 0.6833 - val_loss: 0.8735 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8280 - accuracy: 0.6833 - val_loss: 0.8696 - val_accuracy: 0.6000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8238 - accuracy: 0.6833 - val_loss: 0.8657 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8198 - accuracy: 0.6833 - val_loss: 0.8619 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8157 - accuracy: 0.6833 - val_loss: 0.8582 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8116 - accuracy: 0.6833 - val_loss: 0.8545 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8077 - accuracy: 0.6833 - val_loss: 0.8508 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8037 - accuracy: 0.6833 - val_loss: 0.8473 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7997 - accuracy: 0.6833 - val_loss: 0.8436 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7957 - accuracy: 0.6833 - val_loss: 0.8399 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7918 - accuracy: 0.6833 - val_loss: 0.8362 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7878 - accuracy: 0.6833 - val_loss: 0.8325 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7839 - accuracy: 0.6833 - val_loss: 0.8288 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7801 - accuracy: 0.6833 - val_loss: 0.8252 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7762 - accuracy: 0.6833 - val_loss: 0.8215 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7724 - accuracy: 0.6833 - val_loss: 0.8176 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7685 - accuracy: 0.6833 - val_loss: 0.8140 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7647 - accuracy: 0.6833 - val_loss: 0.8104 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7609 - accuracy: 0.6833 - val_loss: 0.8067 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7572 - accuracy: 0.6833 - val_loss: 0.8032 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7534 - accuracy: 0.6833 - val_loss: 0.7996 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7499 - accuracy: 0.6833 - val_loss: 0.7960 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7461 - accuracy: 0.6833 - val_loss: 0.7924 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7424 - accuracy: 0.6833 - val_loss: 0.7890 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7388 - accuracy: 0.6917 - val_loss: 0.7855 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7352 - accuracy: 0.6917 - val_loss: 0.7819 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7316 - accuracy: 0.6917 - val_loss: 0.7784 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7282 - accuracy: 0.6917 - val_loss: 0.7750 - val_accuracy: 0.6000\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7246 - accuracy: 0.7000 - val_loss: 0.7715 - val_accuracy: 0.6000\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7211 - accuracy: 0.7000 - val_loss: 0.7683 - val_accuracy: 0.6000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7177 - accuracy: 0.7000 - val_loss: 0.7649 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7142 - accuracy: 0.7000 - val_loss: 0.7614 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7108 - accuracy: 0.7000 - val_loss: 0.7583 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7074 - accuracy: 0.7000 - val_loss: 0.7550 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7041 - accuracy: 0.7000 - val_loss: 0.7517 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7007 - accuracy: 0.7000 - val_loss: 0.7485 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6974 - accuracy: 0.7000 - val_loss: 0.7453 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.7000 - val_loss: 0.7422 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.7000 - val_loss: 0.7393 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.7000 - val_loss: 0.7361 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6844 - accuracy: 0.7000 - val_loss: 0.7332 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6813 - accuracy: 0.7000 - val_loss: 0.7302 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6781 - accuracy: 0.7083 - val_loss: 0.7271 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6750 - accuracy: 0.7083 - val_loss: 0.7241 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6719 - accuracy: 0.7083 - val_loss: 0.7211 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6689 - accuracy: 0.7083 - val_loss: 0.7182 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6659 - accuracy: 0.7083 - val_loss: 0.7152 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6629 - accuracy: 0.7083 - val_loss: 0.7125 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6599 - accuracy: 0.7083 - val_loss: 0.7098 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6570 - accuracy: 0.7083 - val_loss: 0.7069 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6541 - accuracy: 0.7083 - val_loss: 0.7040 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6512 - accuracy: 0.7083 - val_loss: 0.7012 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6484 - accuracy: 0.7083 - val_loss: 0.6985 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.7083 - val_loss: 0.6957 - val_accuracy: 0.6333\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6427 - accuracy: 0.7083 - val_loss: 0.6930 - val_accuracy: 0.6333\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.7083 - val_loss: 0.6904 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6373 - accuracy: 0.7083 - val_loss: 0.6877 - val_accuracy: 0.6333\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6346 - accuracy: 0.7083 - val_loss: 0.6850 - val_accuracy: 0.6333\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6320 - accuracy: 0.7083 - val_loss: 0.6822 - val_accuracy: 0.6333\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.7083 - val_loss: 0.6796 - val_accuracy: 0.6333\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6267 - accuracy: 0.7083 - val_loss: 0.6770 - val_accuracy: 0.6333\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6241 - accuracy: 0.7083 - val_loss: 0.6745 - val_accuracy: 0.6333\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6216 - accuracy: 0.7083 - val_loss: 0.6720 - val_accuracy: 0.6333\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6191 - accuracy: 0.7083 - val_loss: 0.6695 - val_accuracy: 0.6333\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.7083 - val_loss: 0.6670 - val_accuracy: 0.6333\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6142 - accuracy: 0.7083 - val_loss: 0.6643 - val_accuracy: 0.6333\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.7083 - val_loss: 0.6618 - val_accuracy: 0.6333\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6092 - accuracy: 0.7083 - val_loss: 0.6595 - val_accuracy: 0.6333\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.7083 - val_loss: 0.6572 - val_accuracy: 0.6333\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6044 - accuracy: 0.7083 - val_loss: 0.6548 - val_accuracy: 0.6333\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6021 - accuracy: 0.7083 - val_loss: 0.6526 - val_accuracy: 0.6333\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5998 - accuracy: 0.7083 - val_loss: 0.6502 - val_accuracy: 0.6333\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5975 - accuracy: 0.7083 - val_loss: 0.6478 - val_accuracy: 0.6333\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5952 - accuracy: 0.7083 - val_loss: 0.6455 - val_accuracy: 0.6333\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.7083 - val_loss: 0.6432 - val_accuracy: 0.6333\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5907 - accuracy: 0.7083 - val_loss: 0.6409 - val_accuracy: 0.6333\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5885 - accuracy: 0.7083 - val_loss: 0.6387 - val_accuracy: 0.6333\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5863 - accuracy: 0.7083 - val_loss: 0.6364 - val_accuracy: 0.6333\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5842 - accuracy: 0.7083 - val_loss: 0.6341 - val_accuracy: 0.6333\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5821 - accuracy: 0.7083 - val_loss: 0.6319 - val_accuracy: 0.6333\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5800 - accuracy: 0.7083 - val_loss: 0.6299 - val_accuracy: 0.6333\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5779 - accuracy: 0.7083 - val_loss: 0.6279 - val_accuracy: 0.6333\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5760 - accuracy: 0.7083 - val_loss: 0.6256 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5738 - accuracy: 0.7083 - val_loss: 0.6237 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5718 - accuracy: 0.7083 - val_loss: 0.6218 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5698 - accuracy: 0.7083 - val_loss: 0.6197 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5679 - accuracy: 0.7083 - val_loss: 0.6178 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5659 - accuracy: 0.7083 - val_loss: 0.6158 - val_accuracy: 0.6333\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5640 - accuracy: 0.7083 - val_loss: 0.6139 - val_accuracy: 0.6333\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5621 - accuracy: 0.7083 - val_loss: 0.6119 - val_accuracy: 0.6333\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.7083 - val_loss: 0.6101 - val_accuracy: 0.6333\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5584 - accuracy: 0.7083 - val_loss: 0.6082 - val_accuracy: 0.6333\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5565 - accuracy: 0.7083 - val_loss: 0.6064 - val_accuracy: 0.6333\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5548 - accuracy: 0.7083 - val_loss: 0.6048 - val_accuracy: 0.6333\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5529 - accuracy: 0.7083 - val_loss: 0.6029 - val_accuracy: 0.6333\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5511 - accuracy: 0.7083 - val_loss: 0.6010 - val_accuracy: 0.6333\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.7083 - val_loss: 0.5991 - val_accuracy: 0.6333\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5476 - accuracy: 0.7083 - val_loss: 0.5970 - val_accuracy: 0.6333\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5459 - accuracy: 0.7083 - val_loss: 0.5951 - val_accuracy: 0.6333\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.7167 - val_loss: 0.5932 - val_accuracy: 0.6333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5425 - accuracy: 0.7250 - val_loss: 0.5914 - val_accuracy: 0.6333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5409 - accuracy: 0.7250 - val_loss: 0.5895 - val_accuracy: 0.6333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.7250 - val_loss: 0.5877 - val_accuracy: 0.6333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5375 - accuracy: 0.7250 - val_loss: 0.5861 - val_accuracy: 0.6333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5359 - accuracy: 0.7250 - val_loss: 0.5843 - val_accuracy: 0.6333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5344 - accuracy: 0.7250 - val_loss: 0.5827 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5327 - accuracy: 0.7250 - val_loss: 0.5812 - val_accuracy: 0.6333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5312 - accuracy: 0.7250 - val_loss: 0.5797 - val_accuracy: 0.6333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5297 - accuracy: 0.7250 - val_loss: 0.5780 - val_accuracy: 0.6333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5281 - accuracy: 0.7250 - val_loss: 0.5766 - val_accuracy: 0.6333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5267 - accuracy: 0.7250 - val_loss: 0.5748 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5251 - accuracy: 0.7250 - val_loss: 0.5734 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5236 - accuracy: 0.7250 - val_loss: 0.5719 - val_accuracy: 0.6333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5222 - accuracy: 0.7333 - val_loss: 0.5704 - val_accuracy: 0.6667\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.7333 - val_loss: 0.5689 - val_accuracy: 0.6667\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5193 - accuracy: 0.7333 - val_loss: 0.5672 - val_accuracy: 0.6667\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5179 - accuracy: 0.7333 - val_loss: 0.5657 - val_accuracy: 0.7000\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5166 - accuracy: 0.7333 - val_loss: 0.5644 - val_accuracy: 0.6667\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5151 - accuracy: 0.7333 - val_loss: 0.5628 - val_accuracy: 0.7000\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7333 - val_loss: 0.5614 - val_accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5123 - accuracy: 0.7333 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5111 - accuracy: 0.7333 - val_loss: 0.5582 - val_accuracy: 0.7000\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7333 - val_loss: 0.5566 - val_accuracy: 0.7000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5083 - accuracy: 0.7333 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5070 - accuracy: 0.7333 - val_loss: 0.5540 - val_accuracy: 0.7000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5057 - accuracy: 0.7333 - val_loss: 0.5526 - val_accuracy: 0.7000\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.7333 - val_loss: 0.5512 - val_accuracy: 0.7000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.7333 - val_loss: 0.5496 - val_accuracy: 0.7000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5018 - accuracy: 0.7333 - val_loss: 0.5482 - val_accuracy: 0.7000\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.7417 - val_loss: 0.5470 - val_accuracy: 0.7000\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7417 - val_loss: 0.5455 - val_accuracy: 0.7000\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.7417 - val_loss: 0.5440 - val_accuracy: 0.7000\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4970 - accuracy: 0.7417 - val_loss: 0.5430 - val_accuracy: 0.7000\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4957 - accuracy: 0.7417 - val_loss: 0.5417 - val_accuracy: 0.7000\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4946 - accuracy: 0.7417 - val_loss: 0.5403 - val_accuracy: 0.7000\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.7417 - val_loss: 0.5392 - val_accuracy: 0.7000\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.7417 - val_loss: 0.5380 - val_accuracy: 0.7000\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4910 - accuracy: 0.7417 - val_loss: 0.5366 - val_accuracy: 0.7000\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.7417 - val_loss: 0.5354 - val_accuracy: 0.7000\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.7417 - val_loss: 0.5341 - val_accuracy: 0.7000\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.7417 - val_loss: 0.5329 - val_accuracy: 0.7000\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4864 - accuracy: 0.7417 - val_loss: 0.5316 - val_accuracy: 0.7000\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.7417 - val_loss: 0.5304 - val_accuracy: 0.7333\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.7417 - val_loss: 0.5292 - val_accuracy: 0.7333\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.7500 - val_loss: 0.5277 - val_accuracy: 0.7333\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4820 - accuracy: 0.7500 - val_loss: 0.5265 - val_accuracy: 0.7333\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4809 - accuracy: 0.7500 - val_loss: 0.5254 - val_accuracy: 0.7333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4798 - accuracy: 0.7500 - val_loss: 0.5242 - val_accuracy: 0.7333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7583 - val_loss: 0.5229 - val_accuracy: 0.7333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4778 - accuracy: 0.7667 - val_loss: 0.5219 - val_accuracy: 0.7333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.7667 - val_loss: 0.5209 - val_accuracy: 0.7333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.7750 - val_loss: 0.5197 - val_accuracy: 0.7333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4746 - accuracy: 0.7750 - val_loss: 0.5186 - val_accuracy: 0.7333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.7750 - val_loss: 0.5173 - val_accuracy: 0.7333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.7750 - val_loss: 0.5161 - val_accuracy: 0.7333\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4716 - accuracy: 0.7750 - val_loss: 0.5149 - val_accuracy: 0.7333\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7750 - val_loss: 0.5139 - val_accuracy: 0.7333\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.7750 - val_loss: 0.5128 - val_accuracy: 0.7333\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7750 - val_loss: 0.5117 - val_accuracy: 0.7667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4675 - accuracy: 0.7750 - val_loss: 0.5108 - val_accuracy: 0.7333\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4666 - accuracy: 0.7750 - val_loss: 0.5098 - val_accuracy: 0.7333\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4656 - accuracy: 0.7750 - val_loss: 0.5086 - val_accuracy: 0.7667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.7750 - val_loss: 0.5075 - val_accuracy: 0.7667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.7833 - val_loss: 0.5064 - val_accuracy: 0.7667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.7917 - val_loss: 0.5052 - val_accuracy: 0.8000\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.7917 - val_loss: 0.5044 - val_accuracy: 0.8000\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.7917 - val_loss: 0.5033 - val_accuracy: 0.8000\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4598 - accuracy: 0.8000 - val_loss: 0.5021 - val_accuracy: 0.8333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.8000 - val_loss: 0.5009 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4579 - accuracy: 0.8000 - val_loss: 0.4997 - val_accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.8000 - val_loss: 0.4986 - val_accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.8000 - val_loss: 0.4976 - val_accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.7917 - val_loss: 0.4965 - val_accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.7917 - val_loss: 0.4954 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4534 - accuracy: 0.8000 - val_loss: 0.4948 - val_accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.8000 - val_loss: 0.4939 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4515 - accuracy: 0.8000 - val_loss: 0.4929 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4506 - accuracy: 0.8000 - val_loss: 0.4919 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.4907 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4488 - accuracy: 0.8000 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4479 - accuracy: 0.8000 - val_loss: 0.4888 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.8000 - val_loss: 0.4877 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.8000 - val_loss: 0.4867 - val_accuracy: 0.8333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4453 - accuracy: 0.8000 - val_loss: 0.4858 - val_accuracy: 0.8333\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4444 - accuracy: 0.8000 - val_loss: 0.4848 - val_accuracy: 0.8333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.8000 - val_loss: 0.4837 - val_accuracy: 0.8333\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.8000 - val_loss: 0.4827 - val_accuracy: 0.8333\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.8083 - val_loss: 0.4817 - val_accuracy: 0.8333\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.8083 - val_loss: 0.4807 - val_accuracy: 0.8333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.8083 - val_loss: 0.4799 - val_accuracy: 0.8333\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.8083 - val_loss: 0.4789 - val_accuracy: 0.8333\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8083 - val_loss: 0.4780 - val_accuracy: 0.8333\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.8083 - val_loss: 0.4771 - val_accuracy: 0.8333\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.8083 - val_loss: 0.4760 - val_accuracy: 0.8333\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.8167 - val_loss: 0.4748 - val_accuracy: 0.8333\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.8167 - val_loss: 0.4739 - val_accuracy: 0.8333\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.8167 - val_loss: 0.4728 - val_accuracy: 0.8333\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8167 - val_loss: 0.4719 - val_accuracy: 0.8333\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.8167 - val_loss: 0.4708 - val_accuracy: 0.8333\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.8167 - val_loss: 0.4701 - val_accuracy: 0.8333\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.8167 - val_loss: 0.4693 - val_accuracy: 0.8333\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4302 - accuracy: 0.8167 - val_loss: 0.4685 - val_accuracy: 0.8333\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.8250 - val_loss: 0.4674 - val_accuracy: 0.8333\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8333 - val_loss: 0.4665 - val_accuracy: 0.8333\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.4657 - val_accuracy: 0.8333\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.8333 - val_loss: 0.4648 - val_accuracy: 0.8333\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8417 - val_loss: 0.4639 - val_accuracy: 0.8333\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.8417 - val_loss: 0.4628 - val_accuracy: 0.8333\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8417 - val_loss: 0.4618 - val_accuracy: 0.8333\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.8417 - val_loss: 0.4608 - val_accuracy: 0.8333\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.8417 - val_loss: 0.4599 - val_accuracy: 0.8333\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.8417 - val_loss: 0.4588 - val_accuracy: 0.8333\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8417 - val_loss: 0.4579 - val_accuracy: 0.8333\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8417 - val_loss: 0.4569 - val_accuracy: 0.8333\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8417 - val_loss: 0.4559 - val_accuracy: 0.8333\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.8417 - val_loss: 0.4548 - val_accuracy: 0.8333\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8417 - val_loss: 0.4538 - val_accuracy: 0.8333\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8417 - val_loss: 0.4528 - val_accuracy: 0.8333\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8500 - val_loss: 0.4518 - val_accuracy: 0.8333\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.8500 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.8500 - val_loss: 0.4503 - val_accuracy: 0.8333\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.8500 - val_loss: 0.4495 - val_accuracy: 0.8333\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8500 - val_loss: 0.4486 - val_accuracy: 0.8333\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8500 - val_loss: 0.4475 - val_accuracy: 0.8667\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8500 - val_loss: 0.4464 - val_accuracy: 0.8667\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8500 - val_loss: 0.4453 - val_accuracy: 0.8667\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4105 - accuracy: 0.8500 - val_loss: 0.4443 - val_accuracy: 0.8667\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4097 - accuracy: 0.8500 - val_loss: 0.4436 - val_accuracy: 0.8667\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8500 - val_loss: 0.4428 - val_accuracy: 0.8667\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4081 - accuracy: 0.8500 - val_loss: 0.4419 - val_accuracy: 0.8667\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4074 - accuracy: 0.8500 - val_loss: 0.4412 - val_accuracy: 0.8667\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8500 - val_loss: 0.4403 - val_accuracy: 0.8667\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4057 - accuracy: 0.8500 - val_loss: 0.4395 - val_accuracy: 0.8667\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8500 - val_loss: 0.4385 - val_accuracy: 0.8667\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4042 - accuracy: 0.8500 - val_loss: 0.4378 - val_accuracy: 0.8667\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8500 - val_loss: 0.4371 - val_accuracy: 0.8667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8500 - val_loss: 0.4362 - val_accuracy: 0.8667\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4020 - accuracy: 0.8500 - val_loss: 0.4355 - val_accuracy: 0.8667\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4011 - accuracy: 0.8500 - val_loss: 0.4346 - val_accuracy: 0.8667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4004 - accuracy: 0.8500 - val_loss: 0.4335 - val_accuracy: 0.8667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8500 - val_loss: 0.4326 - val_accuracy: 0.8667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8500 - val_loss: 0.4318 - val_accuracy: 0.8667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8500 - val_loss: 0.4308 - val_accuracy: 0.9000\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8500 - val_loss: 0.4301 - val_accuracy: 0.9000\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8500 - val_loss: 0.4293 - val_accuracy: 0.9000\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8500 - val_loss: 0.4284 - val_accuracy: 0.9000\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8500 - val_loss: 0.4277 - val_accuracy: 0.9000\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8500 - val_loss: 0.4267 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2773025cb90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(x = X_entreno_normalizado, \n",
    "          y = y_entreno, \n",
    "          epochs = 300,\n",
    "          validation_data = (X_prueba_normalizado, \n",
    "                             y_prueba), \n",
    "          verbose = 1 , \n",
    "          callbacks = [detencion_temprana]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas = pd.DataFrame(modelo.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.054522</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>1.086207</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.049562</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.080966</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.044373</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>1.076084</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.039517</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>1.071397</td>\n",
       "      <td>0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.035126</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>1.066697</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.397150</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.430060</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.396373</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.429276</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.395603</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.428415</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.394863</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.427658</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.394075</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.426736</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.054522  0.358333  1.086207      0.266667\n",
       "1    1.049562  0.366667  1.080966      0.333333\n",
       "2    1.044373  0.383333  1.076084      0.366667\n",
       "3    1.039517  0.391667  1.071397      0.366667\n",
       "4    1.035126  0.425000  1.066697      0.400000\n",
       "..        ...       ...       ...           ...\n",
       "295  0.397150  0.850000  0.430060      0.900000\n",
       "296  0.396373  0.850000  0.429276      0.900000\n",
       "297  0.395603  0.850000  0.428415      0.900000\n",
       "298  0.394863  0.850000  0.427658      0.900000\n",
       "299  0.394075  0.850000  0.426736      0.900000\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metricas[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metricas[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.4267 - accuracy: 0.9000 - 18ms/epoch - 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4267362952232361, 0.8999999761581421]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.evaluate(X_prueba_normalizado,\n",
    "                y_prueba,\n",
    "                verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el Modelo para Despliegue (o puesta en producción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = len(metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notar que el ajuste se hace con todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalizado = normalizador.fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n",
       "       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n",
       "       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n",
       "       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n",
       "       [0.        , 0.41666667, 0.01694915, 0.        ],\n",
       "       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n",
       "       [0.38888889, 1.        , 0.08474576, 0.125     ],\n",
       "       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n",
       "       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n",
       "       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n",
       "       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n",
       "       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n",
       "       [0.08333333, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n",
       "       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n",
       "       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n",
       "       [0.25      , 0.625     , 0.08474576, 0.04166667],\n",
       "       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n",
       "       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n",
       "       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n",
       "       [0.25      , 0.875     , 0.08474576, 0.        ],\n",
       "       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n",
       "       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n",
       "       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n",
       "       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n",
       "       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n",
       "       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n",
       "       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n",
       "       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n",
       "       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n",
       "       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n",
       "       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n",
       "       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n",
       "       [0.75      , 0.5       , 0.62711864, 0.54166667],\n",
       "       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n",
       "       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n",
       "       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n",
       "       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n",
       "       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n",
       "       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n",
       "       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n",
       "       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42372881, 0.375     ],\n",
       "       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n",
       "       [0.5       , 0.375     , 0.62711864, 0.54166667],\n",
       "       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n",
       "       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n",
       "       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n",
       "       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n",
       "       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n",
       "       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n",
       "       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n",
       "       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n",
       "       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n",
       "       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n",
       "       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n",
       "       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n",
       "       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n",
       "       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n",
       "       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n",
       "       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n",
       "       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n",
       "       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n",
       "       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n",
       "       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n",
       "       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n",
       "       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n",
       "       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n",
       "       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n",
       "       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n",
       "       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n",
       "       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n",
       "       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n",
       "       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n",
       "       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n",
       "       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n",
       "       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n",
       "       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n",
       "       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n",
       "       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n",
       "       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n",
       "       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n",
       "       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n",
       "       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n",
       "       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n",
       "       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n",
       "       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n",
       "       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n",
       "       [0.94444444, 0.25      , 1.        , 0.91666667],\n",
       "       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n",
       "       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n",
       "       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n",
       "       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n",
       "       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n",
       "       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n",
       "       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n",
       "       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n",
       "       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n",
       "       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n",
       "       [1.        , 0.75      , 0.91525424, 0.79166667],\n",
       "       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n",
       "       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n",
       "       [0.5       , 0.25      , 0.77966102, 0.54166667],\n",
       "       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n",
       "       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n",
       "       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n",
       "       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n",
       "       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n",
       "       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n",
       "       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n",
       "       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n",
       "       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n",
       "       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n",
       "       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n",
       "       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n",
       "       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n",
       "       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(units = 4,\n",
    "                 activation = 'relu',\n",
    "                input_shape = X_normalizado.shape[1:]))\n",
    "\n",
    "# Ultima capa para clasificación multi-clase\n",
    "#   de las tres especies\n",
    "modelo.add(Dense(units = 3,\n",
    "                 activation = 'softmax'))\n",
    "\n",
    "modelo.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 998us/step - loss: 1.0680 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0633 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0584 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0537 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0490 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0441 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0391 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0346 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0299 - accuracy: 0.3400\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0252 - accuracy: 0.3400\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0204 - accuracy: 0.3467\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0155 - accuracy: 0.3467\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0107 - accuracy: 0.3600\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0063 - accuracy: 0.3600\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0014 - accuracy: 0.3800\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9967 - accuracy: 0.4000\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9915 - accuracy: 0.4333\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9865 - accuracy: 0.4533\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9814 - accuracy: 0.4667\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9766 - accuracy: 0.4533\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9714 - accuracy: 0.4067\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.9665 - accuracy: 0.3467\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9612 - accuracy: 0.4933\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9560 - accuracy: 0.5667\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9510 - accuracy: 0.6067\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9460 - accuracy: 0.6200\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9411 - accuracy: 0.6267\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9363 - accuracy: 0.6467\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9315 - accuracy: 0.6667\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9266 - accuracy: 0.6667\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9219 - accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9169 - accuracy: 0.6667\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9121 - accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9074 - accuracy: 0.6667\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9026 - accuracy: 0.6667\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8976 - accuracy: 0.6667\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8930 - accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8880 - accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8833 - accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8737 - accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8688 - accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8640 - accuracy: 0.6667\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8593 - accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8542 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8495 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8447 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8400 - accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8352 - accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8304 - accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8257 - accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8212 - accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.8161 - accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8114 - accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8066 - accuracy: 0.6667\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8021 - accuracy: 0.6667\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7972 - accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7925 - accuracy: 0.6667\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7878 - accuracy: 0.6667\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7833 - accuracy: 0.6667\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7787 - accuracy: 0.6667\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7739 - accuracy: 0.6667\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7695 - accuracy: 0.6667\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7648 - accuracy: 0.6667\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7605 - accuracy: 0.6667\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7559 - accuracy: 0.6667\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7515 - accuracy: 0.6667\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7471 - accuracy: 0.6667\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7427 - accuracy: 0.6667\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7385 - accuracy: 0.6667\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7342 - accuracy: 0.6667\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7299 - accuracy: 0.6667\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7257 - accuracy: 0.6667\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7216 - accuracy: 0.6667\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7174 - accuracy: 0.6667\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7134 - accuracy: 0.6667\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.6667\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7052 - accuracy: 0.6667\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7013 - accuracy: 0.6667\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6974 - accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6935 - accuracy: 0.6667\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6895 - accuracy: 0.6667\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.6667\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.6820 - accuracy: 0.6667\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.6783 - accuracy: 0.6667\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6745 - accuracy: 0.6667\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6711 - accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6672 - accuracy: 0.6667\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6667\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6602 - accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6499 - accuracy: 0.6667\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6433 - accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6401 - accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6368 - accuracy: 0.6667\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6337 - accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6306 - accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6276 - accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6245 - accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6186 - accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6129 - accuracy: 0.6733\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6102 - accuracy: 0.6733\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6072 - accuracy: 0.6733\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6046 - accuracy: 0.6867\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6017 - accuracy: 0.6867\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5991 - accuracy: 0.6867\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5964 - accuracy: 0.6867\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5938 - accuracy: 0.6867\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5913 - accuracy: 0.6867\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6933\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5863 - accuracy: 0.6933\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5838 - accuracy: 0.6933\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5814 - accuracy: 0.6933\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6933\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5768 - accuracy: 0.6933\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.6933\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.6933\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.6933\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5676 - accuracy: 0.6933\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5655 - accuracy: 0.6933\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5633 - accuracy: 0.6933\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5613 - accuracy: 0.6933\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5591 - accuracy: 0.6933\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5570 - accuracy: 0.6933\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.6933\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.6933\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.6933\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.6933\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.6933\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5452 - accuracy: 0.6933\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.6933\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5415 - accuracy: 0.6933\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5396 - accuracy: 0.6933\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.6933\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.6933\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.6933\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.6933\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.6933\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.6933\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.6933\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5259 - accuracy: 0.6933\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5243 - accuracy: 0.6933\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.6933\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.6933\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5197 - accuracy: 0.7000\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7000\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7000\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7000\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7067\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7133\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5108 - accuracy: 0.7133\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5094 - accuracy: 0.7200\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5080 - accuracy: 0.7200\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5066 - accuracy: 0.7200\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7200\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5040 - accuracy: 0.7200\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5028 - accuracy: 0.7200\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5015 - accuracy: 0.7200\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7200\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7200\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4975 - accuracy: 0.7200\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4964 - accuracy: 0.7200\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4951 - accuracy: 0.7200\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4940 - accuracy: 0.7267\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4927 - accuracy: 0.7267\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4915 - accuracy: 0.7267\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4904 - accuracy: 0.7333\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7333\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4880 - accuracy: 0.7333\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4869 - accuracy: 0.7333\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4859 - accuracy: 0.7333\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7333\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.7333\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4826 - accuracy: 0.7333\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4815 - accuracy: 0.7333\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4805 - accuracy: 0.7333\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7333\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4784 - accuracy: 0.7333\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7333\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4764 - accuracy: 0.7400\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4754 - accuracy: 0.7400\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4744 - accuracy: 0.7400\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7400\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4725 - accuracy: 0.7400\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4715 - accuracy: 0.7400\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4706 - accuracy: 0.7400\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7400\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7400\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4678 - accuracy: 0.7400\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4669 - accuracy: 0.7400\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4660 - accuracy: 0.7467\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4652 - accuracy: 0.7467\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4643 - accuracy: 0.7467\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4634 - accuracy: 0.7467\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7600\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7667\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7667\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4600 - accuracy: 0.7667\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4592 - accuracy: 0.7667\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4583 - accuracy: 0.7600\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7600\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7667\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7667\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7733\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7733\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7933\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7933\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7933\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7933\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7933\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4498 - accuracy: 0.7933\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4490 - accuracy: 0.7933\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4483 - accuracy: 0.7933\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8000\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8000\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8000\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.8000\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8000\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8000\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8133\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.8133\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8133\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4412 - accuracy: 0.8133\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4405 - accuracy: 0.8133\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8133\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.8133\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4385 - accuracy: 0.8133\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4378 - accuracy: 0.8133\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4372 - accuracy: 0.8133\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.8133\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8133\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8133\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4346 - accuracy: 0.8133\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4339 - accuracy: 0.8133\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4333 - accuracy: 0.8133\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8133\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4321 - accuracy: 0.8133\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4314 - accuracy: 0.8133\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4308 - accuracy: 0.8133\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4302 - accuracy: 0.8200\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.8200\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4290 - accuracy: 0.8267\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8333\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.8333\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4272 - accuracy: 0.8333\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8333\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4260 - accuracy: 0.8333\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8333\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8333\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.8333\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8333\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8333\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.4225 - accuracy: 0.8333\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4220 - accuracy: 0.8333\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8333\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8333\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8333\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4197 - accuracy: 0.8333\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4192 - accuracy: 0.8333\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8333\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4181 - accuracy: 0.8333\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4176 - accuracy: 0.8333\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 865us/step - loss: 0.4170 - accuracy: 0.8400\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4165 - accuracy: 0.8400\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4159 - accuracy: 0.8400\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4154 - accuracy: 0.8400\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4149 - accuracy: 0.8400\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4144 - accuracy: 0.8400\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4138 - accuracy: 0.8400\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4135 - accuracy: 0.8400\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4128 - accuracy: 0.8400\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4123 - accuracy: 0.8400\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4118 - accuracy: 0.8400\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4113 - accuracy: 0.8400\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8400\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4103 - accuracy: 0.8400\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4098 - accuracy: 0.8400\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.8400\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4088 - accuracy: 0.8400\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4083 - accuracy: 0.8400\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.8400\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4073 - accuracy: 0.8400\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4068 - accuracy: 0.8400\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4063 - accuracy: 0.8400\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4058 - accuracy: 0.8400\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8400\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4049 - accuracy: 0.8400\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4044 - accuracy: 0.8400\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4039 - accuracy: 0.8400\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4034 - accuracy: 0.8400\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4030 - accuracy: 0.8400\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8400\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4021 - accuracy: 0.8400\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8400\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8400\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27731491b90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(X_normalizado, y, epochs = epocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save(\"modelo_final_iris.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar el Normalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizador_iris.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(normalizador,'normalizador_iris.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso para predecir una flor nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**\n",
    "\n",
    "Puede ser que las siguientes instrucciones causen un error:\n",
    "\n",
    "AttributeError: 'str' object has no attribute 'decode'\n",
    "\n",
    "Si este es el caso hay que bajar la versión del paquete hp5y.  Se puede hacer de la siguiente forma:\n",
    "\n",
    "pip install 'h5py==2.10.0' --force-reinstall\n",
    "\n",
    "o con Conda:\n",
    "\n",
    "conda install 'h5py==2.10.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_flor = load_model(\"modelo_final_iris.h5\")\n",
    "normalizador_flor = joblib.load(\"normalizador_iris.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_sepalo</th>\n",
       "      <th>ancho_sepalo</th>\n",
       "      <th>long_petalo</th>\n",
       "      <th>ancho_petalo</th>\n",
       "      <th>especie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   long_sepalo  ancho_sepalo  long_petalo  ancho_petalo      especie\n",
       "0          5.1           3.5          1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra_flor = {'long_sepalo':5.1,\n",
    "                 'ancho_sepalo':3.5,\n",
    "                 'long_petalo':1.4,\n",
    "                 'ancho_petalo':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['long_sepalo', 'ancho_sepalo', 'long_petalo', 'ancho_petalo'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestra_flor.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='<U15')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codificador.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La siguiente función utiliza una llamada para predecir la clase en base a datos en una estructura jason\n",
    "\n",
    "A partir del 2021 cambio la forma de hacer la llamada y esta es la indicación:\n",
    "\n",
    "model.predict_classes() is deprecated and will be removed after 2021-01-01. \n",
    "\n",
    "Please use instead: \n",
    "\n",
    "**np.argmax(model.predict(x), axis=-1)**, \n",
    "\n",
    "if your model does multi-class classification (e.g. if it uses a softmax last-layer activation). \n",
    "\n",
    "**(model.predict(x) > 0.5).astype(\"int32\")**, \n",
    "\n",
    "if your model does binary classification (e.g. if it uses a sigmoid last-layer activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devuelve_prediccion(modelo, normalizador, muestra_json):\n",
    "    \n",
    "    # Si fueran muchas más características,\n",
    "    #   probablemente sería bueno codificar\n",
    "    #   una iteración que contruya este arreglo\n",
    "    \n",
    "    long_sep = muestra_json['long_sepalo']\n",
    "    ancho_sep = muestra_json['ancho_sepalo']\n",
    "    long_pet = muestra_json['long_petalo']\n",
    "    ancho_pet = muestra_json['ancho_petalo']\n",
    "    \n",
    "    flor = [[long_sep, ancho_sep,\n",
    "             long_pet, ancho_pet]]\n",
    "    \n",
    "    flor = normalizador.transform(flor)\n",
    "    \n",
    "    clases = np.array(['Iris-setosa', \n",
    "                       'Iris-versicolor', \n",
    "                       'Iris-virginica'])\n",
    "    \n",
    "    #clase_ind = modelo.predict_classes(flor)\n",
    "    clase_ind = np.argmax(modelo.predict(flor), axis = -1)    \n",
    "    \n",
    "    return clases[clase_ind][0]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devuelve_prediccion(modelo_flor,\n",
    "                    normalizador_flor,\n",
    "                    muestra_flor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODIGO PARA DESPLIEGUE:\n",
    "\n",
    "Ponerlo todo en una sola celda para copiarlo ya que será necesario crear un script .py|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "modelo_flor = load_model(\"modelo_final_iris.h5\")\n",
    "normalizador_flor = joblib.load(\"normalizador_iris.pkl\") \n",
    "\n",
    "def devuelve_prediccion(modelo, normalizador, muestra_json):\n",
    "    \n",
    "    # Si fueran muchas más características,\n",
    "    #   probablemente sería bueno codificar\n",
    "    #   una iteración que contruya este arreglo\n",
    "    \n",
    "    long_sep = muestra_json['long_sepalo']\n",
    "    ancho_sep = muestra_json['ancho_sepalo']\n",
    "    long_pet = muestra_json['long_petalo']\n",
    "    ancho_pet = muestra_json['ancho_petalo']\n",
    "    \n",
    "    flor = [[long_sep, ancho_sep,\n",
    "             long_pet, ancho_pet]]\n",
    "    \n",
    "    flor = normalizador.transform(flor)\n",
    "    \n",
    "    clases = np.array(['Iris-setosa', \n",
    "                       'Iris-versicolor', \n",
    "                       'Iris-virginica'])\n",
    "    \n",
    "    clase_ind = modelo.predict_classes(flor)\n",
    "    \n",
    "    return clases[clase_ind][0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra_flor = {'long_sepalo':5.1,\n",
    "                 'ancho_sepalo':3.5,\n",
    "                 'long_petalo':1.4,\n",
    "                 'ancho_petalo':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
